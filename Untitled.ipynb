{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48919ed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'anonymize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Namespace\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manonymize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Anonymizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_evaluation\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset_params\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'anonymize'"
     ]
    }
   ],
   "source": [
    "\n",
    "from operator import sub\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "\n",
    "from anonymize import Anonymizer\n",
    "from models import classifier_evaluation\n",
    "from datasets import get_dataset_params\n",
    "from algorithms import read_tree\n",
    "\n",
    "methods = ['mondrian', 'classic_mondrian', 'topdown'] #['cluster', 'datafly']\n",
    "dataset = ['adult', 'cahousing', 'cmc', 'mgm', 'informs']  # italia\n",
    "k_array = [i for i in range(10, 110, 10)]\n",
    "\n",
    "metrics = ['ncp', 'cav', 'dm']\n",
    "ml_metrics = ['knn', 'svm', 'rf']\n",
    "lcolors = ['orange', 'deepskyblue', 'limegreen', 'magenta']\n",
    "\n",
    "metric_names = [\n",
    "    'Normalized\\nCertainty\\n(lower is better)', \n",
    "    'Average\\nEquivalence\\n(lower is better)', \n",
    "    'Discernibility\\nMetric\\n(lower is better)']\n",
    "\n",
    "ml_metric_names = [\n",
    "    'KNN',\n",
    "    'SVMs',\n",
    "    'RFs'\n",
    "]\n",
    "\n",
    "def sub_plot(result, dataset, methods, metrics, label_x, label_y, figname):\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = len(metrics), ncols = len(dataset), figsize = (35, 30))\n",
    "    \n",
    "    for row, metric in enumerate(metrics):\n",
    "        for col, data in enumerate(dataset):\n",
    "            data = data.encode('utf-8')\n",
    "            sub_data = result[ (data == result['data']) ]\n",
    "            for i, method in enumerate(methods):\n",
    "                method = method.encode('utf-8')\n",
    "                sub = sub_data[ (method == sub_data['method'])]\n",
    "                axis[row, col].plot(sub['k'], sub[metric], color = lcolors[i], label=sub['method'][0].decode('utf-8'))\n",
    "\n",
    "    labels_handles = {\n",
    "        label: handle for ax in fig.axes for handle, label in zip(*ax.get_legend_handles_labels())\n",
    "    }\n",
    "\n",
    "    fig.legend(\n",
    "        labels_handles.values(),\n",
    "        labels_handles.keys(),\n",
    "        loc=\"upper center\",\n",
    "        fontsize=30,\n",
    "        ncol=len(labels_handles.values()))\n",
    "\n",
    "    for ax, col in zip(axis[0], label_x):\n",
    "        ax.set_title(col.upper(), size=20)\n",
    "    \n",
    "    for ax in axis[-1]:\n",
    "        ax.set_xlabel('k', size=20)\n",
    "\n",
    "    for ax, row in zip(axis[:,0], label_y):\n",
    "        ax.set_ylabel(row, size = 30)\n",
    "        ax.get_yaxis().set_label_coords(-0.2, 0.5)\n",
    "    \n",
    "    plt.subplots_adjust(0.075, 0.05, 0.97, 0.95, 0.2, 0.25)\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sub_plot_ml(result, dataset, methods, models, label_x, label_y, figname):\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = len(models), ncols = len(dataset), figsize = (35, 30))\n",
    "    \n",
    "    for col, model in enumerate(models):\n",
    "        model = model.encode('utf-8')\n",
    "        sub_data1 = result[(model == result['model'])] \n",
    "        for row, data in enumerate(dataset):\n",
    "            data = data.encode('utf-8')\n",
    "            sub_data2 = sub_data1[(data == sub_data1['data'])]\n",
    "\n",
    "            for i, method in enumerate(methods):\n",
    "                method = method.encode('utf-8')\n",
    "                sub_data3 = sub_data2[(method == sub_data2['method'])]\n",
    "                if i == 0:\n",
    "                    # Baseline score\n",
    "                    axis[col, row].plot(sub_data3['k'], sub_data3[\"ori_f1\"], '--', color = 'black', label=\"Baseline\")\n",
    "                axis[col, row].plot(sub_data3['k'], sub_data3[\"anon_f1\"], color = lcolors[i], label= sub_data3['method'][0].decode('utf-8'))\n",
    "            \n",
    "    labels_handles = {\n",
    "        label: handle for ax in fig.axes for handle, label in zip(*ax.get_legend_handles_labels())\n",
    "    }\n",
    "\n",
    "    fig.legend(\n",
    "        labels_handles.values(),\n",
    "        labels_handles.keys(),\n",
    "        loc=\"upper center\",\n",
    "        fontsize=30,\n",
    "        ncol=len(labels_handles.values()))\n",
    "\n",
    "    for ax, col in zip(axis[0], label_x):\n",
    "        ax.set_title(col.upper(), size=20)\n",
    "    \n",
    "    for ax in axis[-1]:\n",
    "        ax.set_xlabel('k', size=20)\n",
    "\n",
    "    for ax, row in zip(axis[:,0], label_y):\n",
    "        ax.set_ylabel(row, size = 30)\n",
    "        ax.get_yaxis().set_label_coords(-0.2, 0.5)\n",
    "    \n",
    "    plt.subplots_adjust(0.075, 0.05, 0.97, 0.95, 0.2, 0.25)\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "\n",
    "def plot_metric(col, dataset, methods, metrics, label_x, label_y, figname):\n",
    "    result = np.genfromtxt(\"metric_result\", names = col, dtype = None)\n",
    "    sub_plot(result, dataset, methods, metrics, label_x, label_y, figname)\n",
    "\n",
    "def plot_metric_ml(col, dataset, methods, models, label_x, label_y, figname):\n",
    "    result = np.genfromtxt(\"ml_metric_result\", names = col, dtype=None)\n",
    "    sub_plot_ml(result, dataset, methods, models, label_x, label_y, figname)\n",
    "\n",
    "\n",
    "def run_anon_data():\n",
    "\n",
    "    output = open(\"metric_result\", \"w\")\n",
    "\n",
    "    for data in dataset:\n",
    "        for method in methods:\n",
    "            for k in k_array:\n",
    "                args = Namespace()\n",
    "                args.method = method\n",
    "                args.dataset = data\n",
    "                args.k = k\n",
    "                anonymizer = Anonymizer(args)\n",
    "                ncp, cav_b, cav_a, dm_b, dm_a = anonymizer.anonymize()\n",
    "                result = f'{data} {method} {k} {ncp:.3f} {cav_a:.3f} {dm_a:.3f}'\n",
    "                output.write(result + '\\n')\n",
    "    \n",
    "    output.close()\n",
    "\n",
    "def run_anon_data_ml():\n",
    "    import pandas as pd\n",
    "    data_path = './data'\n",
    "    result_path = './results'\n",
    "    output = open(\"ml_metric_result\", \"w\")\n",
    "\n",
    "    for data in dataset:\n",
    "        gen_path = f'./data/{data}/hierarchies'\n",
    "        data_params = get_dataset_params(data)\n",
    "        QI_INDEX = data_params['qi_index']\n",
    "        IS_CAT = data_params['is_category']\n",
    "        HAS_HIERARCHIES = [True] * len(IS_CAT)\n",
    "        ori_csv = os.path.join(data_path, data, f'{data}.csv')\n",
    "        tmp_df = pd.read_csv(ori_csv, delimiter=';')\n",
    "        ATT_NAMES = list(tmp_df.columns)\n",
    "        ATT_TREES = read_tree(\n",
    "                gen_path, \n",
    "                data, \n",
    "                ATT_NAMES, \n",
    "                QI_INDEX, \n",
    "                HAS_HIERARCHIES)\n",
    "        train_index = os.path.join(data_path, data, f'{data}_train.txt')\n",
    "        val_index = os.path.join(data_path, data, f'{data}_val.txt')\n",
    "        for classifier_name in ml_metrics:\n",
    "            ori_f1 = classifier_evaluation(classifier_name, ori_csv, train_index, val_index, QI_INDEX, IS_CAT)\n",
    "            for method in methods:\n",
    "                for k in k_array:\n",
    "                    anon_csv = os.path.join(result_path, data, method, f'{data}_anonymized_{k}.csv')\n",
    "                    tmp_att_trees = ATT_TREES\n",
    "                    if method == 'classic_mondrian':\n",
    "                        tmp_att_trees = None\n",
    "                    anon_f1 = classifier_evaluation(\n",
    "                        classifier_name, \n",
    "                        ori_csv, \n",
    "                        train_index, \n",
    "                        val_index, \n",
    "                        anon_csv=anon_csv,\n",
    "                        qi_index=QI_INDEX, \n",
    "                        is_cat=IS_CAT,\n",
    "                        att_trees=tmp_att_trees)\n",
    "\n",
    "                    result = f'{data} {method} {k} {classifier_name} {ori_f1:.3f} {anon_f1:.3f}'\n",
    "                    output.write(result + '\\n')\n",
    "    output.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Metric evaluation\n",
    "    # run_anon_data()\n",
    "    # plot_metric(\n",
    "    #     col = [\"data\", \"method\", \"k\", \"ncp\", \"cav\", \"dm\"],\n",
    "    #     metrics = metrics,\n",
    "    #     dataset=dataset,\n",
    "    #     methods=methods,\n",
    "    #     label_x= dataset,\n",
    "    #     label_y = metric_names,\n",
    "    #     figname='./demo/metrics'\n",
    "    # )\n",
    "\n",
    "    run_anon_data_ml()\n",
    "    plot_metric_ml(\n",
    "        col = [\"data\", \"method\", \"k\", \"model\" ,\"ori_f1\", \"anon_f1\"],\n",
    "        dataset=dataset,\n",
    "        methods=methods,\n",
    "        models=ml_metrics,\n",
    "        label_x= dataset,\n",
    "        label_y = ml_metric_names,\n",
    "        figname='./demo/metrics_ml'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dc2c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nt/_rylnbr93rx9mxvwv8nsm7980000gp/T/ipykernel_48151/1338467082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc04bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
