{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938f65f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymize with datafly\n",
      "NCP score (lower is better): 0.257\n",
      "CAVG score (near 1 is better): BEFORE: 0.232 || AFTER: 7.330\n",
      "DM score (lower is better): BEFORE: 2033853 || AFTER: 189674\n",
      "Time execution: 0.140s\n",
      "Anonymize with datafly\n",
      "NCP score (lower is better): 0.257\n",
      "CAVG score (near 1 is better): BEFORE: 0.211 || AFTER: 6.664\n",
      "DM score (lower is better): BEFORE: 2077743 || AFTER: 189674\n",
      "Time execution: 0.138s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/_rylnbr93rx9mxvwv8nsm7980000gp/T/ipykernel_53052/4028902914.py:115: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  result = np.genfromtxt(\"metric_result\", names = col, dtype = None)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not assign tuple of length 6 to structure with 5 fields.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 191\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Metric evaluation\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     run_anon_data()\n\u001b[0;32m--> 191\u001b[0m     \u001b[43mplot_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"ncp\",\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfigname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./demo/metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m#     run_anon_data_ml()\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#     plot_metric_ml(\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#         col = [\"data\", \"method\", \"k\", \"model\" ,\"ori_f1\", \"anon_f1\"],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m#         figname='./demo/metrics_ml'\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 115\u001b[0m, in \u001b[0;36mplot_metric\u001b[0;34m(col, dataset, methods, metrics, label_x, label_y, figname)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metric\u001b[39m(col, dataset, methods, metrics, label_x, label_y, figname):\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric_result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     sub_plot(result, dataset, methods, metrics, label_x, label_y, figname)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/data-anonymization-MfPseODn/lib/python3.9/site-packages/numpy/lib/npyio.py:2389\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   2387\u001b[0m     ddtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, sized_column_types))\n\u001b[1;32m   2388\u001b[0m     mdtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, [\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(sized_column_types)))\n\u001b[0;32m-> 2389\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usemask:\n\u001b[1;32m   2391\u001b[0m     outputmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(masks, dtype\u001b[38;5;241m=\u001b[39mmdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not assign tuple of length 6 to structure with 5 fields."
     ]
    }
   ],
   "source": [
    "\n",
    "from operator import sub\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "\n",
    "from anonymize import Anonymizer\n",
    "from models import classifier_evaluation\n",
    "from datasets import get_dataset_params\n",
    "from algorithms import read_tree\n",
    "\n",
    "methods = ['datafly'] #['cluster', 'datafly'] , 'classic_mondrian', 'topdown' 'mondrian', \n",
    "dataset = ['cmc'] # ['adult', 'cahousing', 'cmc', 'mgm', 'informs']  # italia\n",
    "k_array = [i for i in range(10, 12, 1)]\n",
    "\n",
    "metrics = [ 'cav', 'dm'] # 'ncp',\n",
    "ml_metrics = ['knn', 'svm', 'rf']\n",
    "lcolors = ['orange', 'deepskyblue', 'limegreen', 'magenta']\n",
    "\n",
    "metric_names = [\n",
    "#     'Normalized\\nCertainty\\n(lower is better)', \n",
    "    'Average\\nEquivalence\\n(lower is better)', \n",
    "    'Discernibility\\nMetric\\n(lower is better)']\n",
    "\n",
    "ml_metric_names = [\n",
    "    'KNN',\n",
    "    'SVMs',\n",
    "    'RFs'\n",
    "]\n",
    "\n",
    "def sub_plot(result, dataset, methods, metrics, label_x, label_y, figname):\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = len(metrics), ncols = len(dataset), figsize = (35, 30))\n",
    "    \n",
    "    for row, metric in enumerate(metrics):\n",
    "        for col, data in enumerate(dataset):\n",
    "            data = data.encode('utf-8')\n",
    "            sub_data = result[ (data == result['data']) ]\n",
    "            for i, method in enumerate(methods):\n",
    "                method = method.encode('utf-8')\n",
    "                sub = sub_data[ (method == sub_data['method'])]\n",
    "                axis[row, col].plot(sub['k'], sub[metric], color = lcolors[i], label=sub['method'][0].decode('utf-8'))\n",
    "\n",
    "    labels_handles = {\n",
    "        label: handle for ax in fig.axes for handle, label in zip(*ax.get_legend_handles_labels())\n",
    "    }\n",
    "\n",
    "    fig.legend(\n",
    "        labels_handles.values(),\n",
    "        labels_handles.keys(),\n",
    "        loc=\"upper center\",\n",
    "        fontsize=30,\n",
    "        ncol=len(labels_handles.values()))\n",
    "\n",
    "    for ax, col in zip(axis[0], label_x):\n",
    "        ax.set_title(col.upper(), size=20)\n",
    "    \n",
    "    for ax in axis[-1]:\n",
    "        ax.set_xlabel('k', size=20)\n",
    "\n",
    "    for ax, row in zip(axis[:,0], label_y):\n",
    "        ax.set_ylabel(row, size = 30)\n",
    "        ax.get_yaxis().set_label_coords(-0.2, 0.5)\n",
    "    \n",
    "    plt.subplots_adjust(0.075, 0.05, 0.97, 0.95, 0.2, 0.25)\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sub_plot_ml(result, dataset, methods, models, label_x, label_y, figname):\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = len(models), ncols = len(dataset), figsize = (35, 30))\n",
    "    \n",
    "    for col, model in enumerate(models):\n",
    "        model = model.encode('utf-8')\n",
    "        sub_data1 = result[(model == result['model'])] \n",
    "        for row, data in enumerate(dataset):\n",
    "            data = data.encode('utf-8')\n",
    "            sub_data2 = sub_data1[(data == sub_data1['data'])]\n",
    "\n",
    "            for i, method in enumerate(methods):\n",
    "                method = method.encode('utf-8')\n",
    "                sub_data3 = sub_data2[(method == sub_data2['method'])]\n",
    "                if i == 0:\n",
    "                    # Baseline score\n",
    "                    axis[col, row].plot(sub_data3['k'], sub_data3[\"ori_f1\"], '--', color = 'black', label=\"Baseline\")\n",
    "                axis[col, row].plot(sub_data3['k'], sub_data3[\"anon_f1\"], color = lcolors[i], label= sub_data3['method'][0].decode('utf-8'))\n",
    "            \n",
    "    labels_handles = {\n",
    "        label: handle for ax in fig.axes for handle, label in zip(*ax.get_legend_handles_labels())\n",
    "    }\n",
    "\n",
    "    fig.legend(\n",
    "        labels_handles.values(),\n",
    "        labels_handles.keys(),\n",
    "        loc=\"upper center\",\n",
    "        fontsize=30,\n",
    "        ncol=len(labels_handles.values()))\n",
    "\n",
    "    for ax, col in zip(axis[0], label_x):\n",
    "        ax.set_title(col.upper(), size=20)\n",
    "    \n",
    "    for ax in axis[-1]:\n",
    "        ax.set_xlabel('k', size=20)\n",
    "\n",
    "    for ax, row in zip(axis[:,0], label_y):\n",
    "        ax.set_ylabel(row, size = 30)\n",
    "        ax.get_yaxis().set_label_coords(-0.2, 0.5)\n",
    "    \n",
    "    plt.subplots_adjust(0.075, 0.05, 0.97, 0.95, 0.2, 0.25)\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "\n",
    "def plot_metric(col, dataset, methods, metrics, label_x, label_y, figname):\n",
    "    result = np.genfromtxt(\"metric_result\", names = col, dtype = None)\n",
    "    sub_plot(result, dataset, methods, metrics, label_x, label_y, figname)\n",
    "\n",
    "def plot_metric_ml(col, dataset, methods, models, label_x, label_y, figname):\n",
    "    result = np.genfromtxt(\"ml_metric_result\", names = col, dtype=None)\n",
    "    sub_plot_ml(result, dataset, methods, models, label_x, label_y, figname)\n",
    "\n",
    "\n",
    "def run_anon_data():\n",
    "\n",
    "    output = open(\"metric_result\", \"w\")\n",
    "\n",
    "    for data in dataset:\n",
    "        for method in methods:\n",
    "            for k in k_array:\n",
    "                args = Namespace()\n",
    "                args.method = method\n",
    "                args.dataset = data\n",
    "                args.k = k\n",
    "                anonymizer = Anonymizer(args)\n",
    "                ncp, cav_b, cav_a, dm_b, dm_a = anonymizer.anonymize()\n",
    "                result = f'{data} {method} {k} {ncp:.3f} {cav_a:.3f} {dm_a:.3f}'\n",
    "                output.write(result + '\\n')\n",
    "    \n",
    "    output.close()\n",
    "\n",
    "def run_anon_data_ml():\n",
    "    import pandas as pd\n",
    "    data_path = './data'\n",
    "    result_path = './results'\n",
    "    output = open(\"ml_metric_result\", \"w\")\n",
    "\n",
    "    for data in dataset:\n",
    "        gen_path = f'./data/{data}/hierarchies'\n",
    "        data_params = get_dataset_params(data)\n",
    "        QI_INDEX = data_params['qi_index']\n",
    "        IS_CAT = data_params['is_category']\n",
    "        HAS_HIERARCHIES = [True] * len(IS_CAT)\n",
    "        ori_csv = os.path.join(data_path, data, f'{data}.csv')\n",
    "        tmp_df = pd.read_csv(ori_csv, delimiter=';')\n",
    "        ATT_NAMES = list(tmp_df.columns)\n",
    "        ATT_TREES = read_tree(\n",
    "                gen_path, \n",
    "                data, \n",
    "                ATT_NAMES, \n",
    "                QI_INDEX, \n",
    "                HAS_HIERARCHIES)\n",
    "        train_index = os.path.join(data_path, data, f'{data}_train.txt')\n",
    "        val_index = os.path.join(data_path, data, f'{data}_val.txt')\n",
    "        for classifier_name in ml_metrics:\n",
    "            ori_f1 = classifier_evaluation(classifier_name, ori_csv, train_index, val_index, QI_INDEX, IS_CAT)\n",
    "            for method in methods:\n",
    "                for k in k_array:\n",
    "                    anon_csv = os.path.join(result_path, data, method, f'{data}_anonymized_{k}.csv')\n",
    "                    tmp_att_trees = ATT_TREES\n",
    "                    if method == 'classic_mondrian':\n",
    "                        tmp_att_trees = None\n",
    "                    anon_f1 = classifier_evaluation(\n",
    "                        classifier_name, \n",
    "                        ori_csv, \n",
    "                        train_index, \n",
    "                        val_index, \n",
    "                        anon_csv=anon_csv,\n",
    "                        qi_index=QI_INDEX, \n",
    "                        is_cat=IS_CAT,\n",
    "                        att_trees=tmp_att_trees)\n",
    "\n",
    "                    result = f'{data} {method} {k} {classifier_name} {ori_f1:.3f} {anon_f1:.3f}'\n",
    "                    output.write(result + '\\n')\n",
    "    output.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Metric evaluation\n",
    "    run_anon_data()\n",
    "    plot_metric(\n",
    "        col = [\"data\", \"method\", \"k\", \"ncp\", \"cav\", \"dm\"],  # \n",
    "        metrics = metrics,\n",
    "        dataset=dataset,\n",
    "        methods=methods,\n",
    "        label_x= dataset,\n",
    "        label_y = metric_names,\n",
    "        figname='./demo/metrics'\n",
    "    )\n",
    "\n",
    "#     run_anon_data_ml()\n",
    "#     plot_metric_ml(\n",
    "#         col = [\"data\", \"method\", \"k\", \"model\" ,\"ori_f1\", \"anon_f1\"],\n",
    "#         dataset=dataset,\n",
    "#         methods=methods,\n",
    "#         models=ml_metrics,\n",
    "#         label_x= dataset,\n",
    "#         label_y = ml_metric_names,\n",
    "#         figname='./demo/metrics_ml'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab06d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
