{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c19bfa0-50a9-4caa-89e1-ff2218f0f142",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "### Step-by-step anonymisation of MVR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dbc77ae-7d91-4efc-9eca-d220149158a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### TODOS:\n",
    "\n",
    "- Hash number plate, look at: https://towardsdatascience.com/anonymise-sensitive-data-in-a-pandas-dataframe-column-with-hashlib-8e7ef397d91f\n",
    "- Apply k-anonymity (e.g., Mondrian) to selected columns, such as Age, Year, or\n",
    "- Put Age into pre-defined groups, eg., 0-14, 15-24, 25 - 44, 45-64, 65+\n",
    "- Apply Faker on names\n",
    "- Create an abstract ColumnAnonymiser class, takes column data type, and target policy as inputs. Implement AgeAnonymiser, NZNumberPlateAnonymiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fdb9f09-c61b-4a26-8575-8ea65f9cf07a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('mvr_synthetic_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff121dde-d63a-4d5c-ae13-588aa7fdac2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Mondrian algorithm\n",
    "\n",
    "Mondrian is a Top-down greedy data anonymization algorithm for achieving k-anonymity in data anonymization. \n",
    "\n",
    "It works by partitioning the sensitive attributes of a dataset into groups, ensuring that each group contains at least k individuals. Here's a step-by-step guide on how to use the Mondrian algorithm for k-anonymization:\n",
    "\n",
    "1. Define the sensitive attributes: Identify the attributes in your dataset that need to be protected and anonymized. These are typically the attributes that can uniquely identify individuals, such as names, addresses, or social security numbers.\n",
    "\n",
    "2. Define the quasi-identifiers: Quasi-identifiers are non-sensitive attributes that can potentially be combined to identify individuals indirectly. Examples include age, gender, or zip code. Identify the quasi-identifiers in your dataset that will be used for partitioning.\n",
    "\n",
    "3. Sort the dataset: Sort the dataset based on the quasi-identifiers. This step ensures that similar individuals are grouped together.\n",
    "\n",
    "4. Select a partitioning attribute: Choose one quasi-identifier to start the partitioning process. Typically, the attribute with the highest information loss (i.e., the most discriminating attribute) is selected first.\n",
    "\n",
    "5. Determine the splitting point: Determine the optimal splitting point for the chosen partitioning attribute. The splitting point should divide the dataset into two homogeneous groups, maximizing the anonymity of each group.\n",
    "\n",
    "6. Recursively partition the data: Split the dataset at the determined splitting point, creating two new subsets. Repeat the partitioning process on each subset, selecting a new partitioning attribute at each step, until the desired k-anonymity level is achieved.\n",
    "\n",
    "8. Repeat for other partitioned subsets: If any of the partitioned subsets have fewer than k individuals, repeat the partitioning process on those subsets to ensure they meet the k-anonymity requirement.\n",
    "\n",
    "9. Evaluate and validate the anonymization: Assess the level of k-anonymity achieved by examining the resulting dataset. Validate that the sensitive attributes have been adequately protected and that the utility of the data is still preserved for the intended analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e00c8d1-336a-4575-8788-b722ec86c20d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Process the age group: Generalize the values: Generalize the values of the sensitive attributes within each partitioned group to further anonymize the data. For example, if the sensitive attribute is age, you can generalize it to age ranges (e.g., 20-30, 30-40) instead of specific ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea1905d4-90d4-4ae1-8f1a-cb71c68f96e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from faker import Faker\n",
    "from faker_vehicle import VehicleProvider\n",
    "\n",
    "class ColumnAnonymiser:\n",
    "    def __init__(self, data_type):\n",
    "        self.data_type = data_type\n",
    "    @abstractmethod\n",
    "    def anonymise(self, column):\n",
    "        raise NotImplementedError(\"Anonymise method not implemented.\")\n",
    "\n",
    "class AgeAnonymiser(ColumnAnonymiser):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"age\")\n",
    "\n",
    "    def anonymise(self, column):\n",
    "        age_groups = {\n",
    "            0: \"0-14\",\n",
    "            15: \"15-24\",\n",
    "            25: \"25-44\",\n",
    "            45: \"45-64\",\n",
    "            65: \"65+\"\n",
    "        }\n",
    "\n",
    "        def map_age_group(age):\n",
    "            for group_start, group_name in age_groups.items():\n",
    "                if age <= group_start:\n",
    "                    return group_name\n",
    "            return \"65+\"\n",
    "\n",
    "        return column.apply(map_age_group)\n",
    "\n",
    "class NZNumberPlateAnonymiser(ColumnAnonymiser):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"number_plate\")\n",
    "\n",
    "    def anonymise(self, column):\n",
    "        # use faker_vehicle to anonymise number plate\n",
    "        fake = Faker()\n",
    "        vehicle_provider = VehicleProvider(fake)\n",
    "        return column.apply(lambda x: vehicle_provider.numerify('###-####'))\n",
    "\n",
    "class NameAnonymiser(ColumnAnonymiser):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"name\")\n",
    "\n",
    "    def anonymise(self, column):\n",
    "        faker = Faker()\n",
    "        return column.apply(lambda x: faker.name())\n",
    "\n",
    "# Mondrian algorithm for k-anonymity\n",
    "def apply_mondrian_algorithm(df, k, quasi_identifiers):\n",
    "    # Sort the dataset based on the quasi-identifiers\n",
    "    sorted_df = df.sort_values(by=quasi_identifiers)\n",
    "\n",
    "    # Apply Mondrian algorithm recursively\n",
    "    k_anonymous_df = partition_dataset(sorted_df, k, quasi_identifiers)\n",
    "\n",
    "    # Check if the resulting dataset satisfies k-anonymity\n",
    "    if len(k_anonymous_df) >= k:\n",
    "        print(\"Dataset satisfies k-anonymity.\")\n",
    "    else:\n",
    "        print(\"Dataset does not satisfy k-anonymity.\")\n",
    "\n",
    "    return k_anonymous_df\n",
    "\n",
    "def partition_dataset(df, k, quasi_identifiers):\n",
    "    # Check if the dataset satisfies k-anonymity\n",
    "    if len(df) >= k:\n",
    "        return df\n",
    "    else:\n",
    "        # Select the most discriminating attribute for partitioning\n",
    "        attribute = select_partitioning_attribute(df, quasi_identifiers)\n",
    "\n",
    "        # Determine the optimal splitting point for the attribute\n",
    "        splitting_point = determine_splitting_point(df, attribute)\n",
    "\n",
    "        # Split the dataset into two subsets based on the splitting point\n",
    "        subset1 = df[df[attribute] <= splitting_point]\n",
    "        subset2 = df[df[attribute] > splitting_point]\n",
    "\n",
    "        # Recursively partition the subsets\n",
    "        return pd.concat([partition_dataset(subset1, k, quasi_identifiers), partition_dataset(subset2, k, quasi_identifiers)])\n",
    "\n",
    "def select_partitioning_attribute(df, quasi_identifiers):\n",
    "    # Select the attribute with the highest information loss\n",
    "    # In this example, we can choose the attribute with the highest cardinality\n",
    "    cardinalities = [df[attr].nunique() for attr in quasi_identifiers]\n",
    "\n",
    "    return quasi_identifiers[cardinalities.index(max(cardinalities))]\n",
    "\n",
    "def determine_splitting_point(df, attribute):\n",
    "    # Determine the splitting point for the given attribute\n",
    "    # In this example, we can choose the median value\n",
    "    return df[attribute].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "866f189d-6192-4719-9bfa-e2eba2f90702",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the anonymisers\n",
    "age_anonymiser = AgeAnonymiser()\n",
    "number_plate_anonymiser = NZNumberPlateAnonymiser()\n",
    "name_anonymiser = NameAnonymiser()\n",
    "\n",
    "# Apply anonymisation on specific columns\n",
    "df['Age'] = age_anonymiser.anonymise(df['Age'])\n",
    "df['NumberPlate'] = number_plate_anonymiser.anonymise(df['NumberPlate'])\n",
    "df['Name'] = name_anonymiser.anonymise(df['Name'])\n",
    "\n",
    "# Selected columns for k-anonymity\n",
    "selected_columns = ['Age', 'Year']\n",
    "k = 2  # k-anonymity level\n",
    "\n",
    "# Apply Mondrian algorithm for k-anonymity on selected columns\n",
    "def compute_equivalence_classes(df, quasi_identifiers):\n",
    "    eq_classes = defaultdict(int)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        key = tuple(row[qi] for qi in quasi_identifiers)\n",
    "        eq_classes[key] += 1\n",
    "    \n",
    "    return eq_classes\n",
    "\n",
    "def is_k_anonymous(dataset, quasi_identifiers, k):\n",
    "    eq_classes = compute_equivalence_classes(dataset, quasi_identifiers)\n",
    "    \n",
    "    for count in eq_classes.values():\n",
    "        if count < k:\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "k_anonymous_df = apply_mondrian_algorithm(df, k, selected_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d25b3655-7819-4509-8f21-97c6ff45de45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "k_anonymous_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5512a5f3-93b6-4328-a379-dd347fbfc861",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Information loss\n",
    "\n",
    "To determine the information loss after applying anonymization techniques, we need to compare the uniqueness/distinctiveness of the data before and after anonymization. \n",
    "\n",
    "A common metric used to measure information loss is entropy.Entropy measures the amount of uncertainty or randomness in a dataset. \n",
    "- Higher entropy indicates more diversity and uniqueness in the data\n",
    "- lower entropy suggests more homogeneity and less information. \n",
    "\n",
    "Therefore, by comparing the entropy of the original dataset with the anonymized dataset, you can get an estimate of the information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c938e86-a02d-4500-8bd8-5da849538380",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(column):\n",
    "    value_counts = column.value_counts()\n",
    "    total_count = len(column)\n",
    "    entropy = 0\n",
    "\n",
    "    for count in value_counts:\n",
    "        probability = count / total_count\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    if (entropy == 0):\n",
    "        raise NotImplementedError(\"Entropy cannot be 0\")\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "# Calculate entropy of the original dataset\n",
    "original_entropy = calculate_entropy(df['Age'])\n",
    "print(\"Original Entropy:\", original_entropy)\n",
    "\n",
    "# Calculate entropy of the anonymized dataset\n",
    "anonymized_entropy = calculate_entropy(df['Age'])\n",
    "print(\"Anonymized Entropy:\", anonymized_entropy)\n",
    "\n",
    "# Calculate information loss\n",
    "information_loss = original_entropy - anonymized_entropy\n",
    "print(\"Information Loss:\", information_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f07b5c14-d1c2-4956-8c3f-992c70ab08ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Try other selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21598b8-c4fb-4534-ba08-7d79a0e7a112",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the list of quasi-identifiers\n",
    "quasi_identifiers = [\n",
    "    ['CarMake', 'CarModel', 'Year'],\n",
    "    ['Age', 'Gender'],\n",
    "]\n",
    "\n",
    "# Apply is_k_anonymous to each element in the big list\n",
    "k = 3  # Specify the desired k value for k-anonymity\n",
    "for qi in quasi_identifiers:\n",
    "    k_anonymous_df = apply_mondrian_algorithm(df, k, qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73d5e68-8386-4554-a6f7-bc24d058e3b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "mvr_anonymisation-code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
